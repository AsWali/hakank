/*

 From http:  reasoning.eas.asu.edu/lpmln/examples/lpmln2al/taxi.lpmln
  """
  Conside a program where you know that you are going to be Late 
  if you don't get a Taxi.

  Since we have put a hard constraint that we cannot be late the probability of being 
  Late is going to be 0. The probability of there being a NoTaxi comes out to be 71 %. 
  {NoTaxi = T, Late = F} satisfies the second soft rule and the hard constraint. Hence 
  the probability for this model comes out to be e\textsuperscript{2}/(
  e\textsuperscript{2} + e\textsuperscript{1}) which comes out to be 73\%
  \begin{lstlisting}
  Late 4.9995e-05
  NoTaxi 0.711979
  \end{lstlisting}
  """

  Note: Since lpmln use weights instead of probability, I don't know how to get the no_taxi as 0.71
  Hmm in the lpmln there's an example where the weights are corresponding to percentages:
     0.5 -> -1.6094
     0.8 -> -0.2231
  which is ln(0.5) and ln(0.8)

  But this don't help us here, since the weights are positive, 1 and 2....

  Cf ~/cplint/taxi.pl
     ~/blog/taxi.blog
     ~/psi/taxi.psi

*/

// Marginal:
//     {"late":false,"no_taxi":false} : 0.8695652173913044
//     {"late":false,"no_taxi":true} : 0.13043478260869565
var model = function() {
    
    // There is a chance for a taxi to be not available
    var no_taxi = flip(0.3);

    // You are going to be late if you don't get a taxi
    var late = no_taxi ? flip(0.65) : false;
       
    // But you certainly cannot be late no matter what situation.
    // Hence this constraint is encoded as a hard rule
    condition(late == false);
    return {late:late,
            no_taxi:no_taxi
           };

}

// var d = Infer(model);
var d = Infer({method:"enumerate"},model);
display(d);
